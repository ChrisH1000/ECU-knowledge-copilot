# Local model configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b-instruct

# Embedding configuration
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
EMBEDDING_DEVICE=cpu

# Storage paths
DOCS_PATH=data/docs
VECTORSTORE_PATH=data/vectorstore
CACHE_PATH=logs/cache.json